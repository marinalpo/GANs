### **_Name_** 
experiment_3

### **_Location_** 
`/data/Ponc/VOS-ForeGAN/experiment_3/`

### **_Details_**
- We try a new way of combining A and C of Gf. We use the expression:

Ifg1 = A·Iw1 + (1 - A)·C

The interpretation of this expression is the following: A should learn to keep the information coming from Iw1 and C should learn what should be modified from Iw1.

- lambda_rec  = 10
- lambda_Df   = 10
- lambda_Dfgp = 5

### **_Results_**

:heavy_check_mark: Fake images generated by Gf & Gb look super real.

![GitHub Logo](/experiments/imgs/experiment_03/fake_break_gif.gif)
![GitHub Logo](/experiments/imgs/experiment_03/fake_blackswan_gif.gif)
![GitHub Logo](/experiments/imgs/experiment_03/fake_bear_gif.gif)
![GitHub Logo](/experiments/imgs/experiment_03/fake_bus_gif.gif)

:heavy_check_mark: Generated foregrounds capture motion of the object, this did not happened before

:x: Generated foregrounds do not represent as good as before the appearance of the object, it looks kind of brighter.

![GitHub Logo](/experiments/imgs/experiment_03/fg_blackswan_gif.gif)

:heavy_check_mark: Mask is learning what parts of the previous image should remain and what should be modified.

:x: Obviously, this mask is not the appropriated to mask the generated background because is not a mask that segment the foreground, is a mask that learns what information to keep from previous image.

![GitHub Logo](/experiments/imgs/experiment_03/mask_blackswan_gif.gif)

:x: Gb did not learn that it had to impaint. In addition, since the foreground appearance was poor and the mask was bad, the background took part of the foreground to reconstruct the image (talk to octavia&xavi about gradients when backprop)

![GitHub Logo](/experiments/imgs/experiment_03/bg_bear_gif.gif)

### **_Conclusions_**
- The mask that is used to mask the background to generate should be created from Ifg1. [Experiment 4]
- We should try training first with L1 loss and then lowering lambda_rec to focus more in adversarial losses